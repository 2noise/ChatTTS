<div align="center">

<a href="https://trendshift.io/repositories/10489" target="_blank"><img src="https://trendshift.io/api/badge/repositories/10489" alt="2noise%2FChatTTS | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>

# ChatTTS
Un mod√®le de parole g√©n√©ratif pour le dialogue quotidien.

[![Licence](https://img.shields.io/github/license/2noise/ChatTTS?style=for-the-badge)](https://github.com/2noise/ChatTTS/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/ChatTTS.svg?style=for-the-badge&color=green)](https://pypi.org/project/ChatTTS)

[![Huggingface](https://img.shields.io/badge/ü§ó%20-Models-yellow.svg?style=for-the-badge)](https://huggingface.co/2Noise/ChatTTS)
[![Open In Colab](https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&logo=googlecolab&color=525252)](https://colab.research.google.com/github/2noise/ChatTTS/blob/main/examples/ipynb/colab.ipynb)
[![Discord](https://img.shields.io/badge/Discord-7289DA?style=for-the-badge&logo=discord&logoColor=white)](https://discord.gg/Ud5Jxgx5yD)

[**English**](../../README.md) | [**ÁÆÄ‰Ωì‰∏≠Êñá**](../cn/README.md) | [**Êó•Êú¨Ë™û**](../jp/README.md) | [**–†—É—Å—Å–∫–∏–π**](../ru/README.md) | [**Espa√±ol**](../es/README.md)| **Fran√ßais**  | [**ÌïúÍµ≠Ïñ¥**](../kr/README.md)

</div>

## Introduction
> [!Note]
> Ce d√©p√¥t contient l'infrastructure de l'algorithme et quelques exemples simples.

> [!Tip]
> Pour les produits finaux √©tendus pour les utilisateurs, veuillez consulter le d√©p√¥t index [Awesome-ChatTTS](https://github.com/libukai/Awesome-ChatTTS/tree/en) maintenu par la communaut√©.

ChatTTS est un mod√®le de synth√®se vocale con√ßu sp√©cifiquement pour les sc√©narios de dialogue tels que les assistants LLM.

### Langues prises en charge
- [x] Anglais
- [x] Chinois
- [ ] √Ä venir...

### Points forts
> Vous pouvez vous r√©f√©rer √† **[cette vid√©o sur Bilibili](https://www.bilibili.com/video/BV1zn4y1o7iV)** pour une description d√©taill√©e.

1. **Synth√®se vocale conversationnelle**: ChatTTS est optimis√© pour les t√¢ches bas√©es sur le dialogue, permettant une synth√®se vocale naturelle et expressive. Il prend en charge plusieurs locuteurs, facilitant les conversations interactives.
2. **Contr√¥le granulaire**: Le mod√®le peut pr√©dire et contr√¥ler des caract√©ristiques prosodiques fines, y compris le rire, les pauses et les interjections.
3. **Meilleure prosodie**: ChatTTS d√©passe la plupart des mod√®les TTS open-source en termes de prosodie. Nous fournissons des mod√®les pr√©-entra√Æn√©s pour soutenir la recherche et le d√©veloppement.

### Dataset & Mod√®le
- Le mod√®le principal est entra√Æn√© avec des donn√©es audio en chinois et en anglais de plus de 100 000 heures.
- La version open-source sur **[HuggingFace](https://huggingface.co/2Noise/ChatTTS)** est un mod√®le pr√©-entra√Æn√© de 40 000 heures sans SFT.

### Roadmap
- [x] Open-source du mod√®le de base de 40k heures et du fichier spk_stats.
- [x] G√©n√©ration audio en streaming.
- [ ] Open-source de la version 40k heures avec contr√¥le multi-√©motions.
- [ ] ChatTTS.cpp (nouveau d√©p√¥t dans l'organisation `2noise` est bienvenu)

### Avertissement
> [!Important]
> Ce d√©p√¥t est √† des fins acad√©miques uniquement.

Il est destin√© √† un usage √©ducatif et de recherche, et ne doit pas √™tre utilis√© √† des fins commerciales ou l√©gales. Les auteurs ne garantissent pas l'exactitude, l'exhaustivit√© ou la fiabilit√© des informations. Les informations et les donn√©es utilis√©es dans ce d√©p√¥t sont √† des fins acad√©miques et de recherche uniquement. Les donn√©es obtenues √† partir de sources accessibles au public, et les auteurs ne revendiquent aucun droit de propri√©t√© ou de copyright sur les donn√©es.

ChatTTS est un syst√®me de synth√®se vocale puissant. Cependant, il est tr√®s important d'utiliser cette technologie de mani√®re responsable et √©thique. Pour limiter l'utilisation de ChatTTS, nous avons ajout√© une petite quantit√© de bruit haute fr√©quence pendant l'entra√Ænement du mod√®le de 40 000 heures et compress√© la qualit√© audio autant que possible en utilisant le format MP3, pour emp√™cher les acteurs malveillants de l'utiliser potentiellement √† des fins criminelles. En m√™me temps, nous avons entra√Æn√© en interne un mod√®le de d√©tection et pr√©voyons de l'open-source √† l'avenir.

### Contact
> Les issues/PRs sur GitHub sont toujours les bienvenus.

#### Demandes formelles
Pour les demandes formelles concernant le mod√®le et la feuille de route, veuillez nous contacter √† **open-source@2noise.com**.

#### Discussion en ligne
##### 1. Groupe QQ (application sociale chinoise)
- **Groupe 1**, 808364215 (Complet)
- **Groupe 2**, 230696694 (Complet)
- **Groupe 3**, 933639842 (Complet)
- **Groupe 4**, 608667975

##### 2. Serveur Discord
Rejoignez en cliquant [ici](https://discord.gg/Ud5Jxgx5yD).

## Pour commencer
### Cloner le d√©p√¥t
```bash
git clone https://github.com/2noise/ChatTTS
cd ChatTTS
```

### Installer les d√©pendances
#### 1. Installation directe
```bash
pip install --upgrade -r requirements.txt
```

#### 2. Installer depuis conda
```bash
conda create -n chattts
conda activate chattts
pip install -r requirements.txt
```

#### Optionnel : Installer TransformerEngine si vous utilisez un GPU NVIDIA (Linux uniquement)
> [!Note]
> Le processus d'installation est tr√®s lent.

> [!Warning]
> L'adaptation de TransformerEngine est actuellement en cours de d√©veloppement et NE PEUT PAS fonctionner correctement pour le moment.
> Installez-le uniquement √† des fins de d√©veloppement.

```bash
pip install git+https://github.com/NVIDIA/TransformerEngine.git@stable
```

#### Optionnel : Installer FlashAttention-2 (principalement GPU NVIDIA)
> [!Note]
> Voir les appareils pris en charge dans la [documentation Hugging Face](https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2).

> [!Warning]
> Actuellement, FlashAttention-2 ralentira la vitesse de g√©n√©ration selon [ce probl√®me](https://github.com/huggingface/transformers/issues/26990). 
> Installez-le uniquement √† des fins de d√©veloppement.

```bash
pip install flash-attn --no-build-isolation
```

### D√©marrage rapide
> Assurez-vous que vous √™tes dans le r√©pertoire racine du projet lorsque vous ex√©cutez ces commandes ci-dessous.

#### 1. Lancer WebUI
```bash
python examples/web/webui.py
```

#### 2. Inf√©rence par ligne de commande
> Cela enregistrera l'audio sous ‚Äò./output_audio_n.mp3‚Äô

```bash
python examples/cmd/run.py "Votre premier texte." "Votre deuxi√®me texte."
```

## Installation

1. Installer la version stable depuis PyPI
```bash
pip install ChatTTS
```

2. Installer la derni√®re version depuis GitHub
```bash
pip install git+https://github.com/2noise/ChatTTS
```

3. Installer depuis le r√©pertoire local en mode d√©veloppement
```bash
pip install -e .
```

### Utilisation de base

```python
import ChatTTS
import torch
import torchaudio

chat = ChatTTS.Chat()
chat.load(compile=False) # D√©finissez sur True pour de meilleures performances

texts = ["METTEZ VOTRE PREMIER TEXTE ICI", "METTEZ VOTRE DEUXI√àME TEXTE ICI"]

wavs = chat.infer(texts)

torchaudio.save("output1.wav", torch.from_numpy(wavs[0]), 24000)
```

### Utilisation avanc√©e

```python
###################################
# √âchantillonner un locuteur √† partir d'une distribution gaussienne.

rand_spk = chat.sample_random_speaker()
print(rand_spk) # sauvegardez-le pour une r√©cup√©ration ult√©rieure du timbre

params_infer_code = ChatTTS.Chat.InferCodeParams(
    spk_emb = rand_spk, # ajouter le locuteur √©chantillonn√© 
    temperature = .3,   # en utilisant une temp√©rature personnalis√©e
    top_P = 0.7,        # top P d√©code
    top_K = 20,         # top K d√©code
)

###################################
# Pour le contr√¥le manuel au niveau des phrases.

# utilisez oral_(0-9), laugh_(0-2), break_(0-7) 
# pour g√©n√©rer un token sp√©cial dans le texte √† synth√©tiser.
params_refine_text = ChatTTS.Chat.RefineTextParams(
    prompt='[oral_2][laugh_0][break_6]',
)

wavs = chat.infer(
    texts,
    params_refine_text=params_refine_text,
    params_infer_code=params_infer_code,
)

###################################
# Pour le contr√¥le manuel au niveau des mots.

text = 'Quel est [uv_break]votre plat anglais pr√©f√©r√©?[laugh][lbreak]'
wavs = chat.infer(text, skip_refine_text=True, params_refine_text=params_refine_text,  params_infer_code=params_infer_code)
torchaudio.save("output2.wav", torch.from_numpy(wavs[0]), 24000)
```

<details open>
  <summary><h4>Exemple : auto-pr√©sentation</h4></summary>

```python
inputs_en = """
chat T T S est un mod√®le de synth√®se vocale con√ßu pour les applications de dialogue.
[uv_break]il prend en charge les entr√©es en langues mixtes [uv_break]et offre des capacit√©s multi-locuteurs
avec un contr√¥le pr√©cis des √©l√©ments prosodiques comme 
[uv_break]le rire[uv_break][laugh], [uv_break]les pauses, [uv_break]et l'intonation.
[uv_break]il d√©livre une parole naturelle et expressive,[uv_break]donc veuillez
[uv_break]utiliser le projet de mani√®re responsable √† vos risques et p√©rils.[uv_break]
""".replace('\n', '') # L'anglais est encore exp√©rimental.

params_refine_text = ChatTTS.Chat.RefineTextParams(
    prompt='[oral_2][laugh_0][break_4]',
)

audio_array_en = chat.infer(inputs_en, params_refine_text=params_refine_text)
torchaudio.save("output3.wav", torch.from_numpy(audio_array_en[0]), 24000)
```

<table>
<tr>
<td align="center">

**locuteur masculin**

</td>
<td align="center">

**locutrice f√©minine**

</td>
</tr>
<tr>
<td align="center">

[locuteur masculin](https://github.com/2noise/ChatTTS/assets/130631963/e0f51251-db7f-4d39-a0e9-3e095bb65de1)

</td>
<td align="center">

[locutrice f√©minine](https://github.com/2noise/ChatTTS/assets/130631963/f5dcdd01-1091-47c5-8241-c4f6aaaa8bbd)

</td>
</tr>
</table>


</details>

## FAQ

#### 1. De combien de VRAM ai-je besoin ? Quelle est la vitesse d'inf√©rence ?
Pour un clip audio de 30 secondes, au moins 4 Go de m√©moire GPU sont n√©cessaires. Pour le GPU 4090, il peut g√©n√©rer de l'audio correspondant √† environ 7 tokens s√©mantiques par seconde. Le Facteur Temps R√©el (RTF) est d'environ 0.3.

#### 2. La stabilit√© du mod√®le n'est pas suffisante, avec des probl√®mes tels que des locuteurs multiples ou une mauvaise qualit√© audio.
C'est un probl√®me qui se produit g√©n√©ralement avec les mod√®les autoregressifs (pour bark et valle). Il est g√©n√©ralement difficile √† √©viter. On peut essayer plusieurs √©chantillons pour trouver un r√©sultat appropri√©.

#### 3. En plus du rire, pouvons-nous contr√¥ler autre chose ? Pouvons-nous contr√¥ler d'autres √©motions ?
Dans le mod√®le actuellement publi√©, les seules unit√©s de contr√¥le au niveau des tokens sont `[laugh]`, `[uv_break]`, et `[lbreak]`. Dans les futures versions, nous pourrions open-source des mod√®les avec des capacit√©s de contr√¥le √©motionnel suppl√©mentaires.

## Remerciements
- [bark](https://github.com/suno-ai/bark), [XTTSv2](https://github.com/coqui-ai/TTS) et [valle](https://arxiv.org/abs/2301.02111) d√©montrent un r√©sultat TTS remarquable par un syst√®me de style autoregressif.
- [fish-speech](https://github.com/fishaudio/fish-speech) r√©v√®le la capacit√© de GVQ en tant que tokenizer audio pour la mod√©lisation LLM.
- [vocos](https://github.com/gemelo-ai/vocos) qui est utilis√© comme vocodeur pr√©-entra√Æn√©.

## Appr√©ciation sp√©ciale
- [wlu-audio lab](https://audio.westlake.edu.cn/) pour les exp√©riences d'algorithme pr√©coce.

## Merci √† tous les contributeurs pour leurs efforts
[![contributors](https://contrib.rocks/image?repo=2noise/ChatTTS)](https://github.com/2noise/ChatTTS/graphs/contributors)

<div align="center">

  ![counter](https://counter.seku.su/cmoe?name=chattts&theme=mbs)

</div>
